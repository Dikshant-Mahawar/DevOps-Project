---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: salon-backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: salon-backend
  template:
    metadata:
      labels:
        app: salon-backend
    spec:
      containers:
        - name: backend
          image: harsh4710/salon-backend:latest
          ports:
            - containerPort: 8000

          resources:
            requests:
              cpu: "100m"
            limits:
              cpu: "500m"

          env:

            # ================================
            # üí° Ollama URL Configuration
            # ================================
            # INTERNAL Kubernetes Ollama (Recommended)
            - name: OLLAMA_URL
              value: "http://ollama-service:11434/api/generate"

            # EXTERNAL ngrok Ollama (Use only if needed)
            # - name: OLLAMA_URL
            #   value: "https://gigantesque-apolonia-agrobiologic.ngrok-free.dev/api/generate"

            # - name: OLLAMA_URL
            #   value: "https://estrella-predependent-shiftingly.ngrok-free.dev/api/generate"

            # ================================
            # üîê Sensitive credentials
            # ================================
            - name: OLLAMA_USER
              valueFrom:
                secretKeyRef:
                  name: ollama-secret
                  key: OLLAMA_USER

            - name: OLLAMA_PASS
              valueFrom:
                secretKeyRef:
                  name: ollama-secret
                  key: OLLAMA_PASS

---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  type: NodePort
  selector:
    app: salon-backend
  ports:
    - port: 8000
      targetPort: 8000
      nodePort: 30799
